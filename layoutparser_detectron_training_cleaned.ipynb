{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Detectron2 Layout Analysis Training and Inference Notebook\n",
        "This notebook fine-tunes a Detectron2 layout model on your custom dataset and provides utilities for building a predictor, inference (single image, batch, PDF), and evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup Dependencies\n",
        "Installs required packages. Run once per environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install tqdm\n",
        "!pip install \"Pillow==9.5.0\" #use a downgrade version of PIL\n",
        "!pip install torchvision\n",
        "!pip install torch \n",
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git@v0.4#egg=detectron2'\n",
        "!pip install -U layoutparser\n",
        "!pip install pytesseract\n",
        "!pip install tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Imports & Configuration\n",
        "Imports libraries, sets paths, and configures hyperparameters. Update paths before running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import layoutparser as lp\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from pdf2image import convert_from_path\n",
        "import cv2, matplotlib.pyplot as plt\n",
        "# Dataset paths\n",
        "DATA_DIR = Path('/path/to/dataset')\n",
        "TRAIN_IMAGES = DATA_DIR/'images'\n",
        "VAL_IMAGES   = DATA_DIR/'images'\n",
        "TRAIN_ANN    = DATA_DIR/'annotations/train.json'\n",
        "VAL_ANN      = DATA_DIR/'annotations/val.json'\n",
        "PRETRAINED_WEIGHTS = 'your path to model weights'\n",
        "OUTPUT_DIR   = Path('./output')\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "# Hyperparameters\n",
        "NUM_CLASSES        = 5  # PubLayNet classes\n",
        "BACKBONE_FREEZE_AT = 2\n",
        "LEARNING_RATE      = 1e-4\n",
        "MAX_ITER           = 5000\n",
        "IMS_PER_BATCH      = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Register COCO Datasets\n",
        "Registers train/val sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances('my_train', {}, str(TRAIN_ANN), str(TRAIN_IMAGES))\n",
        "register_coco_instances('my_val',   {}, str(VAL_ANN),   str(VAL_IMAGES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f17f6c5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "# List all registered datasets\n",
        "# print(\"Registered datasets:\", DatasetCatalog.list())\n",
        "\n",
        "metadata = MetadataCatalog.get(\"my_train\")\n",
        "print(\"Image root:\", metadata.image_root)\n",
        "print(\"Annotation file:\", metadata.json_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Initialization\n",
        "Loads pretrained PubLayNet weights and applies overrides."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cfg = get_cfg()\n",
        "#rmb change the config if needed based on the model used\n",
        "cfg.merge_from_file(\"lp://PubLayNet/mask_rcnn_X_101_32x8d_FPN_3x/config\")\n",
        "cfg.MODEL.WEIGHTS = 'your path to pretrained weights'\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
        "cfg.MODEL.BACKBONE.FREEZE_AT = BACKBONE_FREEZE_AT\n",
        "cfg.SOLVER.BASE_LR = LEARNING_RATE\n",
        "cfg.SOLVER.MAX_ITER = MAX_ITER\n",
        "cfg.SOLVER.IMS_PER_BATCH = IMS_PER_BATCH\n",
        "cfg.MODEL.MASK_ON = False # set to false if you dont want to train mask\n",
        "cfg.DATASETS.TRAIN = ('my_train',)\n",
        "cfg.DATASETS.TEST = ('my_val',)\n",
        "cfg.OUTPUT_DIR = str(OUTPUT_DIR/'model_outputs')\n",
        "\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training\n",
        "Defines hook and starts training from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from detectron2.engine import DefaultTrainer, HookBase\n",
        "from tqdm import tqdm\n",
        "class TQDMWithLossHook(HookBase):\n",
        "    def before_train(self):\n",
        "        self.pbar = tqdm(total=self.trainer.max_iter, desc=\"Training\", unit=\"iter\")\n",
        "\n",
        "    def after_step(self):\n",
        "        storage   = self.trainer.storage\n",
        "        loss_dict = storage.latest()\n",
        "        raw       = loss_dict.get(\"total_loss\", None)\n",
        "\n",
        "        # Unpack tuple if necessary\n",
        "        if isinstance(raw, (tuple, list)):\n",
        "            loss_value = raw[0]\n",
        "        else:\n",
        "            loss_value = raw\n",
        "\n",
        "        # Now it's safe to float()\n",
        "        if loss_value is not None:\n",
        "            self.pbar.set_postfix(loss=float(loss_value))\n",
        "        else:\n",
        "            self.pbar.set_postfix(loss=\"N/A\")\n",
        "\n",
        "        self.pbar.update(1)\n",
        "\n",
        "    def after_train(self):\n",
        "        self.pbar.close()\n",
        "\n",
        "\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.register_hooks([TQDMWithLossHook()])\n",
        "trainer.resume_or_load(resume=False)  #IMPORTANT!! fresh weights, only when we first start the training\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Build Predictor\n",
        "Creates DefaultPredictor with trained cfg and explicit checkpoint path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from detectron2.engine import DefaultPredictor\n",
        "# After training completes, load the final checkpoint\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, 'model_final.pth')  # trained weights\n",
        "\n",
        "# Pick an inference-only threshold here:\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Inference Utilities\n",
        "Helper functions for single, batch, and PDF inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def single_inference(image_path, predictor, save_path=None, show=False):\n",
        "    img = cv2.imread(str(image_path))\n",
        "    outputs = predictor(img)\n",
        "    vis = lp.draw_box(img, outputs['instances'].pred_boxes, box_width=2)\n",
        "    if save_path: cv2.imwrite(str(save_path), vis)\n",
        "    if show: plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)); plt.axis('off')\n",
        "    return outputs\n",
        "\n",
        "def batch_inference(input_dir, output_dir, predictor):\n",
        "    output_dir = Path(output_dir); output_dir.mkdir(exist_ok=True)\n",
        "    for img_file in Path(input_dir).glob('*.jpg'):\n",
        "        single_inference(img_file, predictor, save_path=output_dir/img_file.name)\n",
        "\n",
        "def pdf_inference(pdf_path, image_dir, output_dir, predictor, dpi=200):\n",
        "    pages = convert_from_path(str(pdf_path), dpi=dpi)\n",
        "    image_dir = Path(image_dir); image_dir.mkdir(exist_ok=True)\n",
        "    for i, page in enumerate(pages, start=1):\n",
        "        jpg = image_dir/f'page_{i}.jpg'; page.save(jpg, 'JPEG')\n",
        "    batch_inference(image_dir, output_dir, predictor)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e80b8772",
      "metadata": {},
      "source": [
        "## 7.1 Single-Image Inference Example\n",
        "Run detection on one image and display the result inline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c582b90e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Single-image inference demo\n",
        "from pathlib import Path\n",
        "\n",
        "img_path = Path('/path/to/some/image.jpg')\n",
        "outputs = single_inference(\n",
        "    image_path=img_path,\n",
        "    predictor=predictor,\n",
        "    show=True               # will plt.imshow() the box visualization\n",
        ")\n",
        "print(outputs['instances'].to('cpu'))  # view raw box/tensor data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d901d909",
      "metadata": {},
      "source": [
        "## 7.2 Batch Inference Example\n",
        "Process all JPEGs in a folder and write visualized outputs to another.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f86fe776",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Batch inference demo\n",
        "input_folder  = '/path/to/jpg/folder'\n",
        "output_folder = '/path/to/save/results'\n",
        "batch_inference(\n",
        "    input_dir=input_folder,\n",
        "    output_dir=output_folder,\n",
        "    predictor=predictor\n",
        ")\n",
        "print(f\"Wrote visualizations to {output_folder}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f65a722",
      "metadata": {},
      "source": [
        "## 8.3 PDF Inference Example\n",
        "Convert each PDF page to JPEG, then run inference on every page.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ff3aa2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# PDF inference demo\n",
        "pdf_file     = '/path/to/document.pdf'\n",
        "tmp_img_dir  = './temp_pages'\n",
        "result_dir   = './pdf_results'\n",
        "pdf_inference(\n",
        "    pdf_path=pdf_file,\n",
        "    image_dir=tmp_img_dir,\n",
        "    output_dir=result_dir,\n",
        "    predictor=predictor,\n",
        "    dpi=150         # adjust resolution if needed\n",
        ")\n",
        "print(f\"Pages processed and outputs saved under {result_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Evaluation\n",
        "Runs COCO evaluation on validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator('my_val', cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
        "val_loader = build_detection_test_loader(cfg, 'my_val')\n",
        "metrics = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
        "print(metrics)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
